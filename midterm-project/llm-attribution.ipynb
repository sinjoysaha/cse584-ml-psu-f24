{"cells":[{"cell_type":"markdown","metadata":{},"source":["# LLM Attribution Problem"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install transformers==4.44.2"]},{"cell_type":"code","execution_count":133,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T17:12:02.515352Z","iopub.status.busy":"2024-10-04T17:12:02.514498Z","iopub.status.idle":"2024-10-04T17:12:02.521062Z","shell.execute_reply":"2024-10-04T17:12:02.519988Z","shell.execute_reply.started":"2024-10-04T17:12:02.515309Z"},"trusted":true},"outputs":[],"source":["import torch\n","from datasets import load_dataset\n","from transformers import pipeline, set_seed, BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, TrainerCallback\n","\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, classification_report\n","from tqdm import tqdm\n","import numpy as np\n","import seaborn as sns\n","import re\n","import pandas as pd\n","from collections import defaultdict\n","from copy import deepcopy"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.__version__"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["transformers.__version__"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T15:22:05.100397Z","iopub.status.busy":"2024-10-04T15:22:05.099771Z","iopub.status.idle":"2024-10-04T15:22:05.114776Z","shell.execute_reply":"2024-10-04T15:22:05.113937Z","shell.execute_reply.started":"2024-10-04T15:22:05.100351Z"},"trusted":true},"outputs":[],"source":["set_seed(42)"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["# pipe = pipeline(\"text-generation\", model=\"bigscience/bloomz-1b7\", device=0)\n","pipe = pipeline(\"text-generation\", model=\"gpt2\") #, device=0)"]},{"cell_type":"markdown","metadata":{},"source":["# Creating Datasets"]},{"cell_type":"markdown","metadata":{},"source":["## Collate x_i"]},{"cell_type":"markdown","metadata":{},"source":["### Wiki Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["wiki_ds = load_dataset(\"wikimedia/wikipedia\", \"20231101.en\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sentence_endings = re.compile(r'([A-Z][^.!?]*[.!?])\\s+(?=[A-Z])')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["res = []\n","for p in wiki_ds[\"train\"][0][\"text\"].split(\"\\n\\n\"):\n","    sentences = sentence_endings.findall(p)\n","#     print(sentences)\n","    for sent in sentences:\n","        if len(sent.split()) < 3:\n","            continue\n","        res.append(\" \".join(sent.split()[:5]))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(res), sorted(res)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_wiki_dataset(train_samples=500, num_words=5):\n","    step = 1 # wiki_ds.num_rows[\"train\"]//train_samples\n","    test_samples = train_samples//5\n","    train_offset = 0\n","    val_offset = 300000\n","    test_offset = 500000\n","    def get_split(num_samples, offset):\n","        res = []\n","        ctr = 0\n","        for t in wiki_ds[\"train\"][offset:offset+1000:step][\"text\"]:\n","            if ctr >= num_samples:\n","                print(\"Done\")\n","                break\n","            para = t.split(\"\\n\\n\")\n","            if len(para) < 5:\n","                continue\n","\n","            for p in para:\n","                sentences = sentence_endings.findall(p)\n","#                 print(sentences)\n","                ps = 0\n","                for sent in sentences:\n","                    if len(sent.split()) < 3:\n","                        continue\n","                    res.append((\" \".join(sent.split()[:num_words]), sent))\n","                    ctr += 1\n","                    ps += 1\n","                    if ps >= 2:\n","                        break\n","            \n","        return sorted(list(set(res)))\n","\n","    return (get_split(train_samples, train_offset),\n","            get_split(test_samples, val_offset),\n","            get_split(test_samples, test_offset)\n","           )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["wiki_train, wiki_val, wiki_test = get_wiki_dataset(1000)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(wiki_train), len(wiki_val), len(wiki_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["set(wiki_val).intersection(set(wiki_test)), set(wiki_val).intersection(set(wiki_train)), set(wiki_test).intersection(set(wiki_train)), "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for s, org in wiki_train:\n","    print(s, f\" |{len(s.split())}| \", org)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for s in wiki_val:\n","    print(s, len(s.split()))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for s in wiki_test:\n","    print(s, len(s.split()))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_df(l):\n","    df = pd.DataFrame()\n","    df[\"original_sentence\"] = [s for _, s in l]\n","    df[\"truncated_sentence\"] = [s for s, _ in l]\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["wiki_train_df = get_df(wiki_train)\n","wiki_val_df = get_df(wiki_val)\n","wiki_test_df = get_df(wiki_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["wiki_train_df, wiki_val_df, wiki_test_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["wiki_train_df.to_csv(\"./wiki_train.csv\", index=False)\n","wiki_val_df.to_csv(\"./wiki_val.csv\", index=False)\n","wiki_test_df.to_csv(\"./wiki_test.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pd.read_csv(\"wiki_train.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pd.read_csv(\"wiki_val.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pd.read_csv(\"wiki_test.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["### GSM8K Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["gsm8k_ds = load_dataset(\"openai/gsm8k\", \"main\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["CHAR_LIMIT = 120\n","gsm8k_train_txts = [q for q in gsm8k_ds[\"train\"][\"question\"] if len(q) < CHAR_LIMIT]\n","tv_split = int(len(gsm8k_train_txts) * 0.8)\n","gsm8k_train, gsm8k_val = gsm8k_train_txts[:tv_split], gsm8k_train_txts[tv_split:]\n","gsm8k_test = [q for q in gsm8k_ds[\"test\"][\"question\"] if len(q) < CHAR_LIMIT]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(gsm8k_train), len(gsm8k_val), len(gsm8k_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_gsm_df(l):\n","    df = pd.DataFrame()\n","    df[\"original_sentence\"] = l\n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["gsm8k_train_df = get_gsm_df(gsm8k_train)\n","gsm8k_val_df = get_gsm_df(gsm8k_val)\n","gsm8k_test_df = get_gsm_df(gsm8k_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["gsm8k_train_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["gsm8k_val_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["gsm8k_test_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["gsm8k_train_df.to_csv(\"./gsm8k_train.csv\", index=False)\n","gsm8k_val_df.to_csv(\"./gsm8k_val.csv\", index=False)\n","gsm8k_test_df.to_csv(\"./gsm8k_test.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pd.read_csv(\"gsm8k_train.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pd.read_csv(\"gsm8k_val.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pd.read_csv(\"gsm8k_test.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## Generate model outputs"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["### GPT2"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["MODEL_NAME = \"gpt2\"\n","# MODEL_NAME = \"gpt2-xl\"\n","MODEL_NAME_clean = MODEL_NAME.replace(\"/\", \"-\")\n","MODEL_NAME_clean "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# tokenizer = GPT2Tokenizer.from_pretrained(MODEL_NAME)\n","# tokenizer.pad_token_id = tokenizer.eos_token_id"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["generator = pipeline('text-generation', model=MODEL_NAME, device_map=\"auto\") #, tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{},"source":["### Setup Phi2"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["MODEL_NAME = \"microsoft/phi-2\"\n","MODEL_NAME_clean = MODEL_NAME.replace(\"/\", \"-\")\n","MODEL_NAME_clean "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) #, padding_side='left')\n","# tokenizer.pad_token_id = tokenizer.eos_token_id"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["generator = pipeline('text-generation', model=MODEL_NAME, device_map=\"auto\") #, tokenizer=tokenizer)"]},{"cell_type":"markdown","metadata":{},"source":["### Setup Falcon-7B"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","os.remove(\"state.db\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["MODEL_NAME = \"tiiuae/falcon-7b\"\n","MODEL_NAME_clean = MODEL_NAME.replace(\"/\", \"-\")\n","MODEL_NAME_clean "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME) #, padding=True, padding_side='left')\n","# tokenizer.pad_token_id = tokenizer.eos_token_id"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["generator = pipeline(\n","    \"text-generation\",\n","    model=MODEL_NAME,\n","#     tokenizer=tokenizer,\n","#     torch_dtype=torch.bfloat16,\n","#     trust_remote_code=True,\n","    device_map=\"auto\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["tokenizer(\" efsdf sdf sd sdf sgd f sdf sdf\", padding=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# generated_text = generator(\"A -wide meteorite impact crater\", max_length=MAX_LENGTH, num_return_sequences=1, batch_size=batch_size, do_sample=True, temperature=0.7) #, padding=True)\n","generated_text = generator(batch, max_length=MAX_LENGTH, num_return_sequences=1, batch_size=batch_size, do_sample=True, temperature=0.7, pad_token_id=generator.tokenizer.eos_token_id)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["generated_text"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(tokenizer(generated_text[0][\"generated_text\"])[\"input_ids\"])"]},{"cell_type":"markdown","metadata":{},"source":["### Setup Mistral-7B-Instruct-v0.2"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"\n","MODEL_NAME_clean = MODEL_NAME.replace(\"/\", \"-\").replace(\".\", \"-\")\n","MODEL_NAME_clean "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from huggingface_hub import login\n","access_token_read = \"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\"\n","login(token = access_token_read)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n","# tokenizer.pad_token_id = tokenizer.eos_token_id"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["generator = pipeline(\n","    \"text-generation\",\n","    model=MODEL_NAME,\n","#     tokenizer=tokenizer,\n","#     torch_dtype=torch.bfloat16,\n","#     trust_remote_code=True,\n","    device_map=\"auto\",\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### Text Generation Code"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["generator.tokenizer.pad_token_id = generator.tokenizer.eos_token_id\n","generator.tokenizer.padding_side = 'left'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# DATASET = \"wiki_train\"\n","# DATASET = \"wiki_val\"\n","DATASET = \"wiki_test\"\n","\n","# DATASET = \"gsm8k_train\"\n","# DATASET = \"gsm8k_val\"\n","# DATASET = \"gsm8k_test\"\n","\n","# colname = \"truncated_sentence\"\n","colname = \"original_sentence\""]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["read_df = pd.read_csv(f\"{DATASET}.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["f\"{DATASET}.csv\""]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_out_df = read_df\n","model_out_df[MODEL_NAME_clean] = [None] * len(model_out_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_out_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["MAX_LENGTH = 256"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["batch_size = 64 #32 #1 #32 #16\n","\n","print(MODEL_NAME, MODEL_NAME_clean)\n","for DATASET, colname in zip([\"wiki_train\", \"wiki_val\", \"wiki_test\", \"gsm8k_train\", \"gsm8k_val\", \"gsm8k_test\"], [\"truncated_sentence\", \"truncated_sentence\", \"truncated_sentence\", \"original_sentence\", \"original_sentence\", \"original_sentence\"]):\n","    read_df = pd.read_csv(f\"{DATASET}.csv\")\n","    print(f\"{DATASET}.csv\")\n","    print(f\"{colname=}\")\n","    model_out_df = read_df\n","    model_out_df[MODEL_NAME_clean] = [None] * len(model_out_df)\n","    print(model_out_df)\n","    res = []\n","    for s in tqdm(range(0, len(model_out_df), batch_size)):\n","        batch = model_out_df[colname].loc[s:s+batch_size-1].to_list()\n","        print(len(batch), batch)\n","        generated_text = generator(batch, max_length=MAX_LENGTH, num_return_sequences=1, batch_size=batch_size, do_sample=True, temperature=0.7)\n","        gen_outs = [g[0][\"generated_text\"] for g in generated_text]\n","        res.extend(gen_outs)\n","        print(gen_outs)\n","        model_out_df[MODEL_NAME_clean] = res + [None] * (len(model_out_df) - len(res))\n","        model_out_df.to_csv(f\"{DATASET}_{MODEL_NAME_clean}.csv\", index=False)\n","        print(model_out_df)\n","        print(f\"Saved to {DATASET}_{MODEL_NAME_clean}.csv\")\n","    #     break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["batch_size = 32 #1 #32 # 16\n","res = []\n","for s in tqdm(range(0, len(model_out_df), batch_size)):\n","    batch = model_out_df[colname].loc[s:s+batch_size-1].to_list()\n","    print(len(batch), batch)\n","    generated_text = generator(batch, max_length=MAX_LENGTH, num_return_sequences=1, batch_size=batch_size, do_sample=True, temperature=0.7)\n","    gen_outs = [g[0][\"generated_text\"] for g in generated_text]\n","    res.extend(gen_outs)\n","    print(gen_outs)\n","    model_out_df[MODEL_NAME_clean] = res + [None] * (len(model_out_df) - len(res))\n","    model_out_df.to_csv(f\"{DATASET}_{MODEL_NAME_clean}.csv\", index=False)\n","#     break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[" # batch_size = 32\n","# res = []\n","# for s in tqdm(range(0, len(model_out_df), batch_size)):\n","#     batch = model_out_df[\"truncated_sentence\"].loc[s:s+batch_size-1].to_list()\n","#     print(len(batch), batch)\n","#     generated_text = generator(batch, max_length=MAX_LENGTH, num_return_sequences=1, batch_size=batch_size, do_sample=True, temperature=0.7)\n","#     gen_outs = [g[0][\"generated_text\"] for g in generated_text]\n","#     res.extend(gen_outs)\n","#     print(gen_outs)\n","#     model_out_df[MODEL_NAME_clean] = res + [None] * (len(model_out_df) - len(res))\n","#     model_out_df.to_csv(f\"{DATASET}_{MODEL_NAME_clean}.csv\", index=False)\n","#     break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_out_df"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# model_out_df - test"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_out_df[MODEL_NAME_clean] = res"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model_out_df.to_csv(f\"{DATASET}_{MODEL_NAME_clean}.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pd.read_csv(f\"{DATASET}_{MODEL_NAME_clean}.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# for idx, rw in tqdm(wiki_train_df.iterrows()):\n","#     generated_text = generator(rw[\"truncated_sentence\"], max_length=256, num_return_sequences=1, temperature=0.7)\n","#     genout = generated_text[0][\"generated_text\"]\n","#     print(rw[\"truncated_sentence\"])\n","#     print(genout)\n","#     wiki_train_gpt2_df.loc[idx, \"gpt2\"] = genout\n","# #     input_text = \"Complete the following: \"+rw[\"truncated_sentence\"]\n","# #     print(input_text)\n","# #     generated_text = generator(input_text, max_length=256, num_return_sequences=1, temperature=0.7)\n","# #     print(generated_text[0][\"generated_text\"])\n","#     if idx % 10 == 0:\n","#         wiki_train_gpt2_df.to_csv(\"wiki_train_gpt2.csv\", index=False)\n","# #         break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# for p, ft in train_txt:\n","#     print(f\"RUNNING: {p} : {ft}\")\n","#     gen_txt = pipe(p, num_return_sequences=3)\n","#     for seq in gen_txt:\n","#         print(\"*\", seq[\"generated_text\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for idx, rw in model_out_df.iterrows():\n","    print(\"Input:\", rw[\"truncated_sentence\"])\n","    print(\"Output:\", rw[MODEL_NAME_clean])"]},{"cell_type":"markdown","metadata":{},"source":["## BERT Sequence Classification"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T15:22:23.400476Z","iopub.status.busy":"2024-10-04T15:22:23.399720Z","iopub.status.idle":"2024-10-04T15:22:23.404683Z","shell.execute_reply":"2024-10-04T15:22:23.403527Z","shell.execute_reply.started":"2024-10-04T15:22:23.400432Z"},"trusted":true},"outputs":[],"source":["MAX_LENGTH = 256"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T15:22:24.493369Z","iopub.status.busy":"2024-10-04T15:22:24.492296Z","iopub.status.idle":"2024-10-04T15:22:24.501306Z","shell.execute_reply":"2024-10-04T15:22:24.500298Z","shell.execute_reply.started":"2024-10-04T15:22:24.493316Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Daatsets: ['wiki', 'gsm8k']\n","Using model for sequence classification: bert-base-cased\n","Number of models (classes): 5\n","Models (Classes): ['gpt2', 'gpt2-xl', 'microsoft-phi-2', 'tiiuae-falcon-7b', 'mistralai-Mistral-7B-Instruct-v0-2']\n","{'gpt2': 0, 'gpt2-xl': 1, 'microsoft-phi-2': 2, 'tiiuae-falcon-7b': 3, 'mistralai-Mistral-7B-Instruct-v0-2': 4}\n","{0: 'gpt2', 1: 'gpt2-xl', 2: 'microsoft-phi-2', 3: 'tiiuae-falcon-7b', 4: 'mistralai-Mistral-7B-Instruct-v0-2'}\n"]}],"source":["SEQ_CLF_MODEL = \"bert-base-cased\"\n","\n","CLASS_TO_IDX = {\"gpt2\": 0,\n","               \"gpt2-xl\": 1,\n","               \"microsoft-phi-2\": 2,\n","               \"tiiuae-falcon-7b\": 3, \n","               \"mistralai-Mistral-7B-Instruct-v0-2\": 4}\n","\n","NUM_CLASSES = len(CLASS_TO_IDX.items())\n","IDX_TO_CLASS = {v: k for k, v in CLASS_TO_IDX.items()}\n","CLASSES = [IDX_TO_CLASS[k] for k in IDX_TO_CLASS]\n","DATASETS = [\"wiki\", \"gsm8k\"]\n","SPLITS = [\"train\", \"val\", \"test\"]\n","print(f\"Daatsets: {DATASETS}\")\n","print(f\"Using model for sequence classification: {SEQ_CLF_MODEL}\")\n","print(f\"Number of models (classes): {NUM_CLASSES}\")\n","print(f\"Models (Classes): {CLASSES}\")\n","print(CLASS_TO_IDX)\n","print(IDX_TO_CLASS)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T15:22:26.378273Z","iopub.status.busy":"2024-10-04T15:22:26.377885Z","iopub.status.idle":"2024-10-04T15:22:26.382546Z","shell.execute_reply":"2024-10-04T15:22:26.381583Z","shell.execute_reply.started":"2024-10-04T15:22:26.378234Z"},"trusted":true},"outputs":[],"source":["# import os\n","\n","# for DATASET, colname in zip([\"wiki\", \"gsm8k\"], [\"truncated_sentence\", \"original_sentence\"]):\n","#     for SPLIT in [\"train\", \"val\", \"test\"]:\n","#         MODEL_NAME_clean = \"mistralai-Mistral-7B-Instruct-v0.2\"\n","#         fname = f\"{DATASET}_{SPLIT}_{MODEL_NAME_clean}\"\n","#         rename_to = fname.replace(\".\", \"-\")\n","#         try:\n","#             os.rename(f\"{fname}.csv\", f\"{rename_to}.csv\")\n","#         except:\n","#             pass\n","# #         break"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T15:22:27.580647Z","iopub.status.busy":"2024-10-04T15:22:27.580259Z","iopub.status.idle":"2024-10-04T15:22:27.842554Z","shell.execute_reply":"2024-10-04T15:22:27.841650Z","shell.execute_reply.started":"2024-10-04T15:22:27.580611Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Empty DataFrame\n","Columns: [dataset, split, original_text, model_input, model_output, model]\n","Index: []\n","Reading wiki_train_gpt2.csv\n","Reading wiki_train_gpt2-xl.csv\n","Reading wiki_train_microsoft-phi-2.csv\n","Reading wiki_train_tiiuae-falcon-7b.csv\n","Reading wiki_train_mistralai-Mistral-7B-Instruct-v0-2.csv\n","Reading wiki_val_gpt2.csv\n","Reading wiki_val_gpt2-xl.csv\n","Reading wiki_val_microsoft-phi-2.csv\n","Reading wiki_val_tiiuae-falcon-7b.csv\n","Reading wiki_val_mistralai-Mistral-7B-Instruct-v0-2.csv\n","Reading wiki_test_gpt2.csv\n","Reading wiki_test_gpt2-xl.csv\n","Reading wiki_test_microsoft-phi-2.csv\n","Reading wiki_test_tiiuae-falcon-7b.csv\n","Reading wiki_test_mistralai-Mistral-7B-Instruct-v0-2.csv\n","Reading gsm8k_train_gpt2.csv\n","Reading gsm8k_train_gpt2-xl.csv\n","Reading gsm8k_train_microsoft-phi-2.csv\n","Reading gsm8k_train_tiiuae-falcon-7b.csv\n","Reading gsm8k_train_mistralai-Mistral-7B-Instruct-v0-2.csv\n","Reading gsm8k_val_gpt2.csv\n","Reading gsm8k_val_gpt2-xl.csv\n","Reading gsm8k_val_microsoft-phi-2.csv\n","Reading gsm8k_val_tiiuae-falcon-7b.csv\n","Reading gsm8k_val_mistralai-Mistral-7B-Instruct-v0-2.csv\n","Reading gsm8k_test_gpt2.csv\n","Reading gsm8k_test_gpt2-xl.csv\n","Reading gsm8k_test_microsoft-phi-2.csv\n","Reading gsm8k_test_tiiuae-falcon-7b.csv\n","Reading gsm8k_test_mistralai-Mistral-7B-Instruct-v0-2.csv\n"]}],"source":["df = pd.DataFrame(columns=[\"dataset\", \"split\", \"original_text\", \"model_input\", \"model_output\", \"model\"])\n","print(df)\n","\n","for DATASET, colname in zip(DATASETS, [\"truncated_sentence\", \"original_sentence\"]):\n","    for SPLIT in SPLITS:\n","        for MODEL_NAME_clean in CLASSES:\n","            fname = f\"{DATASET}_{SPLIT}_{MODEL_NAME_clean}.csv\"\n","            print(f\"Reading {fname}\")\n","            read_df = pd.read_csv(fname)\n","#             print(read_df)\n","            read_df[\"dataset\"] = DATASET\n","            read_df[\"split\"] = SPLIT\n","            read_df[\"model\"] = MODEL_NAME_clean\n","            if DATASET == \"gsm8k\":\n","                read_df[\"model_input\"] = read_df[colname]\n","            \n","            if MODEL_NAME_clean == \"mistralai-Mistral-7B-Instruct-v0-2\":\n","                read_df.rename(columns={\"mistralai-Mistral-7B-Instruct-v0.2\": \"model_output\"}, inplace=True)\n","            read_df.rename(columns={\"original_sentence\": \"original_text\",\n","                                    \"truncated_sentence\": \"model_input\",\n","                                    MODEL_NAME_clean: \"model_output\"}, inplace=True)\n","\n","            read_df = read_df[df.columns.to_list()]\n","            df = pd.concat([df, read_df])\n"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T15:22:28.876292Z","iopub.status.busy":"2024-10-04T15:22:28.875575Z","iopub.status.idle":"2024-10-04T15:22:28.886954Z","shell.execute_reply":"2024-10-04T15:22:28.885947Z","shell.execute_reply.started":"2024-10-04T15:22:28.876253Z"},"trusted":true},"outputs":[],"source":["df[\"class\"] = df[\"model\"].map(CLASS_TO_IDX)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T15:22:29.944289Z","iopub.status.busy":"2024-10-04T15:22:29.943887Z","iopub.status.idle":"2024-10-04T15:22:29.962061Z","shell.execute_reply":"2024-10-04T15:22:29.961119Z","shell.execute_reply.started":"2024-10-04T15:22:29.944250Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dataset</th>\n","      <th>split</th>\n","      <th>original_text</th>\n","      <th>model_input</th>\n","      <th>model_output</th>\n","      <th>model</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>wiki</td>\n","      <td>train</td>\n","      <td>A -wide meteorite impact crater is located in ...</td>\n","      <td>A -wide meteorite impact crater</td>\n","      <td>A -wide meteorite impact crater, which has bee...</td>\n","      <td>gpt2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>wiki</td>\n","      <td>train</td>\n","      <td>A 2008 study found that this anthropogenic cha...</td>\n","      <td>A 2008 study found that</td>\n","      <td>A 2008 study found that the majority of the pe...</td>\n","      <td>gpt2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>wiki</td>\n","      <td>train</td>\n","      <td>A 60-gun ship of that name served at the Battl...</td>\n","      <td>A 60-gun ship of that</td>\n","      <td>A 60-gun ship of that caliber, carrying 300 me...</td>\n","      <td>gpt2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>wiki</td>\n","      <td>train</td>\n","      <td>A Centers for Disease Control and Prevention s...</td>\n","      <td>A Centers for Disease Control</td>\n","      <td>A Centers for Disease Control and Prevention s...</td>\n","      <td>gpt2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>wiki</td>\n","      <td>train</td>\n","      <td>A broad categorisation can be made between aim...</td>\n","      <td>A broad categorisation can be</td>\n","      <td>A broad categorisation can be achieved by usin...</td>\n","      <td>gpt2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>gsm8k</td>\n","      <td>test</td>\n","      <td>Jack had $100. Sophia gave him 1/5 of her $100...</td>\n","      <td>Jack had $100. Sophia gave him 1/5 of her $100...</td>\n","      <td>Jack had $100. Sophia gave him 1/5 of her $100...</td>\n","      <td>mistralai-Mistral-7B-Instruct-v0-2</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>gsm8k</td>\n","      <td>test</td>\n","      <td>Mike bought 5 face masks while Johnny bought 2...</td>\n","      <td>Mike bought 5 face masks while Johnny bought 2...</td>\n","      <td>Mike bought 5 face masks while Johnny bought 2...</td>\n","      <td>mistralai-Mistral-7B-Instruct-v0-2</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>gsm8k</td>\n","      <td>test</td>\n","      <td>Digimon had its 20th anniversary.  When it cam...</td>\n","      <td>Digimon had its 20th anniversary.  When it cam...</td>\n","      <td>Digimon had its 20th anniversary.  When it cam...</td>\n","      <td>mistralai-Mistral-7B-Instruct-v0-2</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>gsm8k</td>\n","      <td>test</td>\n","      <td>Sally received the following scores on her mat...</td>\n","      <td>Sally received the following scores on her mat...</td>\n","      <td>Sally received the following scores on her mat...</td>\n","      <td>mistralai-Mistral-7B-Instruct-v0-2</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>66</th>\n","      <td>gsm8k</td>\n","      <td>test</td>\n","      <td>Rose bought five dozens of eggs for $2.40 a do...</td>\n","      <td>Rose bought five dozens of eggs for $2.40 a do...</td>\n","      <td>Rose bought five dozens of eggs for $2.40 a do...</td>\n","      <td>mistralai-Mistral-7B-Instruct-v0-2</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9885 rows Ã— 7 columns</p>\n","</div>"],"text/plain":["   dataset  split                                      original_text  \\\n","0     wiki  train  A -wide meteorite impact crater is located in ...   \n","1     wiki  train  A 2008 study found that this anthropogenic cha...   \n","2     wiki  train  A 60-gun ship of that name served at the Battl...   \n","3     wiki  train  A Centers for Disease Control and Prevention s...   \n","4     wiki  train  A broad categorisation can be made between aim...   \n","..     ...    ...                                                ...   \n","62   gsm8k   test  Jack had $100. Sophia gave him 1/5 of her $100...   \n","63   gsm8k   test  Mike bought 5 face masks while Johnny bought 2...   \n","64   gsm8k   test  Digimon had its 20th anniversary.  When it cam...   \n","65   gsm8k   test  Sally received the following scores on her mat...   \n","66   gsm8k   test  Rose bought five dozens of eggs for $2.40 a do...   \n","\n","                                          model_input  \\\n","0                     A -wide meteorite impact crater   \n","1                             A 2008 study found that   \n","2                               A 60-gun ship of that   \n","3                       A Centers for Disease Control   \n","4                       A broad categorisation can be   \n","..                                                ...   \n","62  Jack had $100. Sophia gave him 1/5 of her $100...   \n","63  Mike bought 5 face masks while Johnny bought 2...   \n","64  Digimon had its 20th anniversary.  When it cam...   \n","65  Sally received the following scores on her mat...   \n","66  Rose bought five dozens of eggs for $2.40 a do...   \n","\n","                                         model_output  \\\n","0   A -wide meteorite impact crater, which has bee...   \n","1   A 2008 study found that the majority of the pe...   \n","2   A 60-gun ship of that caliber, carrying 300 me...   \n","3   A Centers for Disease Control and Prevention s...   \n","4   A broad categorisation can be achieved by usin...   \n","..                                                ...   \n","62  Jack had $100. Sophia gave him 1/5 of her $100...   \n","63  Mike bought 5 face masks while Johnny bought 2...   \n","64  Digimon had its 20th anniversary.  When it cam...   \n","65  Sally received the following scores on her mat...   \n","66  Rose bought five dozens of eggs for $2.40 a do...   \n","\n","                                 model  class  \n","0                                 gpt2      0  \n","1                                 gpt2      0  \n","2                                 gpt2      0  \n","3                                 gpt2      0  \n","4                                 gpt2      0  \n","..                                 ...    ...  \n","62  mistralai-Mistral-7B-Instruct-v0-2      4  \n","63  mistralai-Mistral-7B-Instruct-v0-2      4  \n","64  mistralai-Mistral-7B-Instruct-v0-2      4  \n","65  mistralai-Mistral-7B-Instruct-v0-2      4  \n","66  mistralai-Mistral-7B-Instruct-v0-2      4  \n","\n","[9885 rows x 7 columns]"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T15:22:31.482223Z","iopub.status.busy":"2024-10-04T15:22:31.481567Z","iopub.status.idle":"2024-10-04T15:22:31.673577Z","shell.execute_reply":"2024-10-04T15:22:31.672652Z","shell.execute_reply.started":"2024-10-04T15:22:31.482183Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}],"source":["tokenizer = BertTokenizer.from_pretrained(SEQ_CLF_MODEL)"]},{"cell_type":"code","execution_count":160,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T17:53:39.027803Z","iopub.status.busy":"2024-10-04T17:53:39.027143Z","iopub.status.idle":"2024-10-04T17:53:39.034349Z","shell.execute_reply":"2024-10-04T17:53:39.033295Z","shell.execute_reply.started":"2024-10-04T17:53:39.027760Z"},"trusted":true},"outputs":[],"source":["class LLMAttribDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"]},{"cell_type":"code","execution_count":161,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T17:53:39.373944Z","iopub.status.busy":"2024-10-04T17:53:39.373008Z","iopub.status.idle":"2024-10-04T17:53:39.380883Z","shell.execute_reply":"2024-10-04T17:53:39.379820Z","shell.execute_reply.started":"2024-10-04T17:53:39.373893Z"},"trusted":true},"outputs":[],"source":["class CustomCallback(TrainerCallback):\n","    def __init__(self, trainer) -> None:\n","        super().__init__()\n","        self._trainer = trainer\n","    \n","    def on_step_end(self, args, state, control, **kwargs):\n","        if control.should_evaluate:\n","            control_copy = deepcopy(control)\n","            self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train_\")\n","            return control_copy"]},{"cell_type":"code","execution_count":162,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T17:53:40.072220Z","iopub.status.busy":"2024-10-04T17:53:40.071802Z","iopub.status.idle":"2024-10-04T17:53:40.078952Z","shell.execute_reply":"2024-10-04T17:53:40.077924Z","shell.execute_reply.started":"2024-10-04T17:53:40.072182Z"},"trusted":true},"outputs":[],"source":["def get_dataset(dataset, split):\n","    if dataset==\"all\":\n","        temp_df = df[(df[\"split\"]==split)]\n","    else:\n","        temp_df = df[(df[\"dataset\"]==dataset) & (df[\"split\"]==split)]\n","#     print(temp_df)\n","    clf_input_text = temp_df[\"model_output\"].to_list()\n","    encodings = tokenizer(clf_input_text, truncation=True, padding=\"max_length\", max_length=MAX_LENGTH)\n","    clf_label = temp_df[\"class\"].to_list()\n","    pt_ds = LLMAttribDataset(encodings, clf_label)\n","    print(f\"Created -> Dataset: {dataset} | Split: {split} | Len: {pt_ds.__len__()}\")\n","    return pt_ds"]},{"cell_type":"code","execution_count":163,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T17:53:41.239557Z","iopub.status.busy":"2024-10-04T17:53:41.239186Z","iopub.status.idle":"2024-10-04T17:53:41.245047Z","shell.execute_reply":"2024-10-04T17:53:41.244106Z","shell.execute_reply.started":"2024-10-04T17:53:41.239520Z"},"trusted":true},"outputs":[],"source":["def compute_metrics(p):\n","    preds = p.predictions.argmax(-1)\n","    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='macro')\n","    acc = accuracy_score(p.label_ids, preds)\n","    return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}"]},{"cell_type":"code","execution_count":172,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T18:01:50.247890Z","iopub.status.busy":"2024-10-04T18:01:50.247204Z","iopub.status.idle":"2024-10-04T18:01:50.260445Z","shell.execute_reply":"2024-10-04T18:01:50.259314Z","shell.execute_reply.started":"2024-10-04T18:01:50.247831Z"},"trusted":true},"outputs":[],"source":["def plot_training_loss(log_history):\n","#     train_state_df = pd.DataFrame(trainer.state.log_history, columns=[\"epoch\", \"step\", \"loss\", \"eval_loss\"])\n","    training_loss = [log[\"loss\"] for log in log_history if \"loss\" in log and \"step\" in log]\n","    validation_loss = [log[\"eval_loss\"] for log in log_history if \"eval_loss\" in log]\n","    end_step = min(len(training_loss), len(validation_loss))\n","    training_loss = training_loss[:end_step]\n","    validation_loss = validation_loss[:end_step]\n","    \n","    steps = [log[\"step\"] for log in log_history if \"loss\" in log][:end_step]\n","    \n","    print(len(training_loss), len(validation_loss), len(steps))\n","    \n","    # plot loss\n","    plt.plot(steps, training_loss, label=\"Training Loss\", color='blue')\n","    plt.plot(steps, validation_loss, label=\"Validation Loss\", color='orange')\n","    \n","    plt.xlabel(\"Steps\")\n","    plt.ylabel(\"Loss\")\n","    plt.title(\"Training and Validation Loss Over Time\")\n","    plt.grid(True)\n","    plt.legend()\n","    plt.show()\n","    "]},{"cell_type":"code","execution_count":173,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T18:01:51.493872Z","iopub.status.busy":"2024-10-04T18:01:51.493504Z","iopub.status.idle":"2024-10-04T18:01:51.499384Z","shell.execute_reply":"2024-10-04T18:01:51.498481Z","shell.execute_reply.started":"2024-10-04T18:01:51.493835Z"},"trusted":true},"outputs":[],"source":["def plot_confusion_mat(cm):\n","    plt.figure(figsize=(8, 4))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=TICKS, yticklabels=TICKS)\n","    plt.ylabel('Actual')\n","    plt.xlabel('Predicted')\n","    plt.title('Confusion Matrix')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# get dataset\n","pt_dataset = defaultdict(dict)\n","    for ds in DATASETS+[\"all\"]:\n","        for split in SPLITS:\n","            pt_dataset[ds][split] = get_dataset(ds, split)            "]},{"cell_type":"code","execution_count":176,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T18:03:59.620634Z","iopub.status.busy":"2024-10-04T18:03:59.620243Z","iopub.status.idle":"2024-10-04T18:03:59.636824Z","shell.execute_reply":"2024-10-04T18:03:59.635762Z","shell.execute_reply.started":"2024-10-04T18:03:59.620599Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["gsm8k\n","256\n","1\n","gsm8k-256-1\n"]}],"source":["# Experiments\n","\n","ds = \"gsm8k\"\n","epochs = 1\n","out_dir = f\"{ds}-{MAX_LENGTH}-{epochs}\"\n","\n","print(ds)\n","print(MAX_LENGTH)\n","print(epochs)\n","print(out_dir)\n","\n","def run_experiment():\n","    \n","    print(f\"Allocated memory: {torch.cuda.memory_allocated() / 1024 ** 2} MB\")\n","    print(f\"Cached memory: {torch.cuda.memory_reserved() / 1024 ** 2} MB\")\n","    torch.cuda.empty_cache()\n","    print(\"After emptying cache:\")\n","    print(f\"Allocated memory: {torch.cuda.memory_allocated() / 1024 ** 2} MB\")\n","    print(f\"Cached memory: {torch.cuda.memory_reserved() / 1024 ** 2} MB\")\n","\n","    print(f\"Loading mode: {SEQ_CLF_MODEL}...\")\n","    model = BertForSequenceClassification.from_pretrained(SEQ_CLF_MODEL, num_labels=NUM_CLASSES)\n","    print(\"Model loaded.\")\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    print(f\"Using device: {device}\")\n","    model.to(device)\n","\n","    training_args = TrainingArguments(\n","        output_dir=f\"./results/{out_dir}\",\n","        logging_dir='./logs',\n","        per_device_train_batch_size=32,\n","        per_device_eval_batch_size=16,\n","        num_train_epochs=epochs,\n","        weight_decay=0.01,\n","        eval_strategy=\"steps\",\n","        logging_steps=50,\n","        eval_steps=50,\n","        save_steps=50,     # Save the model every 500 steps\n","        save_total_limit=2,  \n","        report_to=\"none\",  # Disable report to Weights & Biases\n","        load_best_model_at_end=True,\n","    )\n","\n","    trainer = Trainer(\n","        model=model,\n","        args=training_args,\n","        train_dataset=pt_dataset[ds][\"train\"],\n","        eval_dataset=pt_dataset[ds][\"val\"],\n","        compute_metrics=compute_metrics,\n","    )\n","    print(\"Adding Custom Callback\")\n","    trainer.add_callback(CustomCallback(trainer)) \n","    # return trainer    \n","    print(\"Start training...\")\n","    train_results = trainer.train()\n","    print(\"Done training...\")\n","\n","    print(\"Saving trainer state...\")\n","    trainer.save_state()\n","    print(\"Saving best model...\")\n","    trainer.save_model(output_dir=f\"./results/{out_dir}/best_model\")\n","    \n","    print(\"Train set:\")\n","    print(train_results.metrics)\n","    trainer.log_metrics(\"train\", train_results.metrics)\n","    trainer.save_metrics(\"train\", train_results.metrics)\n","    print(\"Validation set:\")\n","    val_results = trainer.evaluate()\n","    print(val_results)\n","    trainer.log_metrics(\"eval\", val_results)\n","    trainer.save_metrics(\"eval\", val_results)\n","    print(\"Test set:\")\n","    test_results = trainer.predict(test_dataset=pt_dataset[ds][\"test\"])\n","    print(test_results.metrics)\n","    trainer.log_metrics(\"test\", test_results.metrics)\n","    trainer.save_metrics(\"test\", test_results.metrics)\n","    \n","    # plots\n","    plot_training_loss(trainer.state.log_history)\n","    \n","    TICKS = ['gpt2',\n","             'gpt2-xl',\n","             'phi-2',\n","             'falcon-7b',\n","             'mistral-7B']\n","    predictions = np.argmax(test_results.predictions, axis=1)\n","    cm = confusion_matrix(test_results.label_ids, predictions)\n","    plot_confusion_mat(cm)\n","    \n","    print(\"All done!\")\n","    \n","    return trainer"]},{"cell_type":"code","execution_count":177,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T18:04:00.933908Z","iopub.status.busy":"2024-10-04T18:04:00.933524Z","iopub.status.idle":"2024-10-04T18:04:01.766151Z","shell.execute_reply":"2024-10-04T18:04:01.765195Z","shell.execute_reply.started":"2024-10-04T18:04:00.933871Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Allocated memory: 4979.15234375 MB\n","Cached memory: 10408.0 MB\n","After emptying cache:\n","Allocated memory: 4979.15234375 MB\n","Cached memory: 5626.0 MB\n","Loading mode: bert-base-cased...\n"]},{"name":"stderr","output_type":"stream","text":["A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n","A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Model loaded.\n","Using device: cuda\n","Adding Custom Callback\n"]}],"source":["trainer = run_experiment()"]},{"cell_type":"code","execution_count":179,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T18:04:29.947873Z","iopub.status.busy":"2024-10-04T18:04:29.947502Z","iopub.status.idle":"2024-10-04T18:04:32.945979Z","shell.execute_reply":"2024-10-04T18:04:32.945036Z","shell.execute_reply.started":"2024-10-04T18:04:29.947839Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Test set:\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["{'test_loss': 1.7380963563919067, 'test_accuracy': 0.18208955223880596, 'test_f1': 0.08085971285244767, 'test_precision': 0.05448897173035104, 'test_recall': 0.18208955223880596, 'test_runtime': 2.9895, 'test_samples_per_second': 112.058, 'test_steps_per_second': 3.68}\n","***** test metrics *****\n","  test_accuracy           =     0.1821\n","  test_f1                 =     0.0809\n","  test_loss               =     1.7381\n","  test_precision          =     0.0545\n","  test_recall             =     0.1821\n","  test_runtime            = 0:00:02.98\n","  test_samples_per_second =    112.058\n","  test_steps_per_second   =       3.68\n"]}],"source":["print(\"Test set:\")\n","test_results = trainer.predict(test_dataset=pt_dataset[ds][\"test\"])\n","print(test_results.metrics)\n","trainer.log_metrics(\"test\", test_results.metrics)\n","trainer.save_metrics(\"test\", test_results.metrics)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":44,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-10-04T16:00:48.770859Z","iopub.status.busy":"2024-10-04T16:00:48.770102Z","iopub.status.idle":"2024-10-04T16:04:04.129046Z","shell.execute_reply":"2024-10-04T16:04:04.128032Z","shell.execute_reply.started":"2024-10-04T16:00:48.770817Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  pid, fd = os.forkpty()\n"]},{"name":"stdout","output_type":"stream","text":["  adding: kaggle/working/results/wiki-256/ (stored 0%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-300/ (stored 0%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-300/trainer_state.json (deflated 73%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-300/model.safetensors (deflated 7%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-300/rng_state.pth (deflated 25%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-300/optimizer.pt (deflated 13%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-300/scheduler.pt (deflated 56%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-300/training_args.bin (deflated 51%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-300/config.json (deflated 53%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-860/ (stored 0%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-860/trainer_state.json (deflated 78%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-860/model.safetensors (deflated 7%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-860/rng_state.pth (deflated 25%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-860/optimizer.pt (deflated 13%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-860/scheduler.pt (deflated 56%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-860/training_args.bin (deflated 51%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-860/config.json (deflated 53%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-850/ (stored 0%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-850/trainer_state.json (deflated 78%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-850/model.safetensors (deflated 7%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-850/rng_state.pth (deflated 25%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-850/optimizer.pt (deflated 13%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-850/scheduler.pt (deflated 55%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-850/training_args.bin (deflated 51%)\n","  adding: kaggle/working/results/wiki-256/checkpoint-850/config.json (deflated 53%)\n"]}],"source":["!zip -r wiki-256-noshuffle.zip /kaggle/working/results/wiki-256"]},{"cell_type":"code","execution_count":45,"metadata":{"execution":{"iopub.execute_input":"2024-10-04T16:06:07.490500Z","iopub.status.busy":"2024-10-04T16:06:07.489673Z","iopub.status.idle":"2024-10-04T16:06:07.497562Z","shell.execute_reply":"2024-10-04T16:06:07.496712Z","shell.execute_reply.started":"2024-10-04T16:06:07.490457Z"},"trusted":true},"outputs":[{"data":{"text/html":["<a href='wiki-256-noshuffle.zip' target='_blank'>wiki-256-noshuffle.zip</a><br>"],"text/plain":["/kaggle/working/wiki-256-noshuffle.zip"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["from IPython.display import FileLink\n","FileLink(r'wiki-256-noshuffle.zip')"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30761,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
